from datetime import datetime, timedelta

import streamlit as st

from ft_gpt import utils
from ft_gpt.ingest.create_engine import create_engine


def reset_chat():
    st.session_state.chat_engine.reset()
    init_chat()


def show_info_text():
    st.header("Folketinget GPT")
    dates = utils.get_dates_of_sittings(reverse=True)
    st.markdown("Hej ğŸ‘‹")
    st.markdown(
        "Jeg er en LLM (Large language model), som kan hjÃ¦lpe dig med at afsÃ¸ge information om hvad der er forgÃ¥et pÃ¥ folketingets mÃ¸der."
    )
    st.markdown(
        f"Jeg har adgang til mÃ¸dereferater i datospÃ¦ndet :red[**{dates[-1]}**] til og med :red[**{dates[0]}**]"
    )

    st.markdown("Indskriv dit spÃ¸rgsmÃ¥l i feltet placeret i bunden af siden ğŸ‘‡")
    st.markdown("")


def init_chat():
    st.session_state.messages = []
    st.session_state.chat_engine.reset()


show_info_text()


@st.cache_resource(show_spinner="Starting engine..")
def load_engine_from_cache():
    return create_engine()


if "chat_engine" not in st.session_state:
    engine = load_engine_from_cache()
    st.session_state.chat_engine = engine


# Initialize chat history
if "messages" not in st.session_state:
    init_chat()

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

prompt = st.chat_input("Hvad har x sagt om y...")

if prompt:
    with st.chat_message(name="User"):
        st.write(prompt)
    with st.spinner("TÃ¦nker..."):
        response = st.session_state.chat_engine.chat(prompt)
        references = [i.metadata["file"] for i in response.source_nodes]
    with st.chat_message(name="LLM"):
        enhanced_response = f"{response.response}\n"
        if references != []:
            for i in references:
                enhanced_response = enhanced_response + f"- :gray[*[{i}]({i})*]\n"
        st.markdown(enhanced_response)

    st.session_state.messages.append(
        {"role": "user", "content": prompt},
    )
    st.session_state.messages.append(
        {"role": "llm", "content": enhanced_response},
    )
